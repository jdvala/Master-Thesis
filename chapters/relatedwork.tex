\ifgerman{\chapter{Verwandte Arbeiten}}{\chapter{Related Work}}
\label{ch:relatedwork}

This chapter regards previous works done in the domain of text classification on legal text. Then we regard work done using  splitting of data into $n$ clusters and then the work done in the classification of multilingual text.

We first regard work about multi-class classification on legal text documents and subsequently general problems of multi-class classification under class imbalance. An approach for more fine-grained document classification has been proposed by Mencia et al. who perform multilabel classification on a large scale problem using EUR-Lex law texts. They predicted 4,000 labels for 19,596  \cite{mencia2010efficient}. We employ their published document collection for training our word embeddings. In contrast though, we examine a setting with high-level labels, bilingual documents, class imbalance and a limited dataset size. Boella et al. added a module in existing software by classifying pieces of law into different categories in accordance with labeled data. This classification takes into account the similarity between laws from different domains, which in turn helps in identification of more of relevant information. 


Maat et al. performed multiclass classification on sentences from Dutch legislation and compared machine learning classifier with pattern based classifier. The sentences were created by dividing the document into categories like definition,  obligation,  repeal, application and provision which are structural parts of a legal document \cite{de2010machine}. Song et al. performed analysis on multilingual opinionated sentences \cite{oro15675}. We have employed similar approach of training the classifiers with sentences created from the documents. Unlike both the approaches, here the whole document is divided into sentences and is assigned label that the document had. 

Previous studies on hierarchical text categorization by Ceci et al. have shown how hierarchical structures can be used to improve the efficiency and efficacy of text classification. They have defined a top-down approach where a document is first classified into a higher-level category (\textit{e.g. Science}) and then into a lower-level category (\textit{e.g Biology, Chemistry..etc}) \cite{Ceci2007}. We are not following the same approach but something similar. Instead of classifying the documents into subcategory we are dividing the data set into $n$ groups and then employ a root classifier to predict which of the $n$ classifiers should be invoked in order to predict the given sentence.    

Gonalves and Quaresma \cite{gonalves2010} have shown the benefit of combining multiple \glspl{SVM} for several languages and classify international agreements of the European Union. Their results indicate that encompassing several languages can improve classifier performance. They set the minimum amount of documents per category to 50, thus limiting the lack of training documents and class imbalance. This is a restriction which we did not apply and another difference is that we use summaries instead of the longer, original text as inputs for our classifiers to focus on their capability to handle difficult datasets. C.-P. Wei et al. argued that when the training t when the training set for a single language is small it is less representative of the target semantic space and a classifier trained on this data set would not yield satisfactory results. They have shown that adding multilingual data for  predefined categories can help in increasing the performance of the classifier \cite{Wei:2014:EPD:2566999.2567111}. The dataset we are using is comparatively less and it is available in multiple languages in the same predefined categories. Hence we use them to see how well our classifier performs on single language and on multiple languages.

Zhang et al. proposed the use of distribution of positive examples in an imbalanced dataset to dynamically determine a threshold which will bring the number of positive and negative examples in the dataset close \cite{Zhang2013ImbalancedMN}. This is somewhat similar to what we have done to resample the dataset. However, contrary to their approach we are not trying to bring the number of positive and negative sample close, instead we are using the number of samples to remove sample from majority class. 
