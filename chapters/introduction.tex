\ifgerman{\chapter{Einführung}}{\chapter{Introduction}}

%- Hintergrund
%- Motivation
%- Ziele
%- Aufgaben
%- Allgemeine Beschreibung des Projektes
%- Worum geht es in dieser Arbeit?
%- Wer hat die Arbeit veranlasst und wozu?
%- Wer soll von den Ergebnissen profitieren?
%- Welches Problem soll gelöst werden? Warum?
%- Unter welchen Umständen braucht man eine Verbesserung?
%- Was ist der Stand der Technik?
%- Welche noch offenen Probleme gibt es?
%- Worin unterscheidet sich mein Ansatz von den bisherigen?
%- Welche Ziele hat die Arbeit?
%- Wie will ich diese Ziele erreichen?
%- Was habe ich im Einzelnen vor?

% \hint{}

% \hint{\ldots\ to be continued \ldots}

\section{Introduction}
\glsresetall
There is an abundance of legal corpora available online. The publications office of the European Union (EU) offers different EU laws such as Treaties, Legal acts, Consolidated texts, International agreements, Preparatory documents and Summaries of EU Legislation. It also provides EU case laws, national laws, and national case laws. Other governments in the EU also publish legal text such as the \textit{gesetze-im-internet} website, the German Federal Ministry of Justice and Consumer Protection and the Federal Office of Justice offerings of every federal law of Germany, the \textit{Library of Congress} for the French law and many more.

Large legal text corpora can be overwhelming and hard to comprehend for non-domain experts, especially when jargon is used. Also, the complexity and the capricious nature of the legal texts is a challenge in itself. It can also be challenging for domain experts handling legal text written for different demographics, with different structure, and in different languages. Some of the most common problems with the legal texts are that it may be coming from different sources (different department of the government or from different governments altogether), it is difficult to know which laws overturn other laws, understanding different lexicon that changes with contexts, authority and over time \cite{boella2012nlp}. These barriers make it challenging to organize and aggregate these legal texts in a coherent manner. Traditional full-text search matches the exact text, and this helps in finding relevant information, but it is still challenging to discover all the relevant information such as in the cases where related words and synonyms are used for search \cite{landthaler2016extending}. To get around this, domain ontologies which map the relationships of synonyms, related words and antonyms are used; however, these are hard to create and difficult to maintain. 

The ongoing advancements in \gls{AI} and Machine Learning which is partly due to the availability of computing power can be promising in mitigating some of the difficulties with legal texts mentioned above. \gls{NLP} is a subset of \gls{AI} that focuses on systems that can learn and understand language. \gls{ANN} are a part of AI which was inspired by the biological neural network of human brain \cite{van2018artificial}. They are a framework comprising many different machine learning algorithms learning complex data. The application of \gls{ANN} is suitable for data that has noise which in case of legal text is having no sole representation of a law, that is the perception of law is in accordance with the requirements and needs. Secondly, there is a poor understanding intrinsic structure which means that there is no single entity which knows all the laws and lastly for the data having changing characteristics \cite{merkl1997exploration}. 

Various methods involving machine learning and \gls{AI} have been developed to solve some of the problems with legal texts described above. de Maat et. al (2010) \cite{de2010machine} have shown the effectiveness of using machine learning algorithms to classify legal text compared to a pattern-based classification task on unseen data. Mozina et. al (2005) \cite{movzina2005argument} showed that argumentation-based machine learning can be made using the justification of the case laws making it suitable for legal domain-specific tasks. Boella et. al (2011) \cite{boella2011using} have shown that sophisticated legal document management systems can be further improved using machine learning, the authors used classification algorithms to classify laws and integrate into an existing system. 



\section{Goals of this Thesis}
This thesis focuses on the classification tasks of legal text. There are various classification algorithms with their advantages and disadvantages. The goal of this thesis is to evaluate these algorithms in various configurations, 

Specifically, this thesis will investigate three questions,

\begin{itemize}
    \item 
        \begin{quote}
        Can deep neural network algorithms like \glsfirst{LSTM} networks perform comparatively to the thoroughly studied text classification algorithms like \glsfirst{SVM}?
        \end{quote}
        
        The \gls{SVM} has been thoroughly studied and applied in text classification \cite{Chau:2008:MLA:1322568.1322643, Fan:2006:ITM:1217741.1217764, Forman:2008:BFS:1458082.1458119,10.1007/BFb0026683,Sebastiani:2002:MLA:505282.505283,oro15675}. \glspl{SVM} have been shown to outperform many classification algorithms, but the sensitivity of the parameters to the classification task makes them difficult to use \cite{10.1007/978-0-387-34747-9_18}. Also the text representation technique used by the \gls{SVM} which is \gls{TF-IDF} does not capture the syntactics and semantics of the text \cite{Corr_a_J_nior_2017}. Many deep learning classification algorithms alleviate the problems that \glspl{SVM} posses, with text representation techniques such as word embeddings capturing the semantics and syntactics of the text to represent its context better.
        
        
    \item 
    \begin{quote}
        General-purpose resources such as pretrained word embeddings are getting better and are available from various sources and trained using different algorithms. As they are trained on large generic web scraped data, are they good enough for the legal domain-specific task?    
    \end{quote}
    Recently, various word embeddings such as BERT (Bidirectional Encoder Representations from Transformers) \cite{devlin2018bert}, Fasttext word vectors in 157 languages \cite{bojanowski2017enriching}, Flair \cite{akbik2018coling} and ELMo \cite{Peters:2018} were released. They, however, use general data scraped from websites like Wikipedia or freely available news and other corpora. These corpora do not cover the highly specialized and specific vocabulary used in the legal text; hence the effectiveness of these word embeddings for a legal domain-specific task has to be investigated.
    
    
    \item
    \begin{quote}
      Deep Neural Network algorithms like \gls{LSTM} can take advantage of multilingual data, as the text representation technique of word embeddings has been shown to work on multilingual data. Thus, the performance of \glspl{LSTM} needs to be investigated in case of monolingual and multilingual data to see if there is any advantage of using multilingual data.
    \end{quote}
     Conventionally, multilingual text classification is done by employing a language detector, which detects the language to be classified and then initiating a classifier that is trained on a specific language. This naive approach does not take advantage of the polylinguality of data for classification for a predefined category which may benefit from this data \cite{Wei:2014:EPD:2566999.2567111}. Recent techniques of learning bilingual word embeddings \cite{D13-1141,NIPS2014_5270} have shown to be improving, for this reason, the effect of multilingual embeddings is to be explored. 
\end{itemize}

\section{Structure of the Thesis}
The thesis is divided into seven chapters. \ref{ch:background} provides details of the various machine learning and deep learning methods, algorithms and information about document categorization. \ref{ch:concept} details the conceptual aspects for all the research questions and the techniques such as data cleaning, data collections that will be used to answer the research questions. \ref{ch:implementation} gives the detailed narrative of the tools used in implementing the concepts, the architecture and the hyperparameters of the algorithms provided in the \ref{ch:concept} and the specifics of how they are implemented. \ref{ch:evaluation} provides details of the evaluation approaches and the results of all the research questions.  \ref{ch:relatedwork} shows the similar work done on the legal dataset, and similar techniques used in training and evaluation of the algorithms. \ref{ch:conclusion} presents the conclusion of the thesis, discusses the limitations of some approaches and future works. 